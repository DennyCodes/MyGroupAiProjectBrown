{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b18a5e-b0b4-48da-b8ed-03361150a44b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (100,2) could not be broadcast to indexing result of shape (100,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(correct_confidences))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Create dummy data with adjusted features\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Initialize layers and activations\u001b[39;00m\n\u001b[1;32m     79\u001b[0m l1 \u001b[38;5;241m=\u001b[39m Layer(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m)  \u001b[38;5;66;03m# Adjusted input_size to match features in X\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mcreate_data\u001b[0;34m(points, classes)\u001b[0m\n\u001b[1;32m     12\u001b[0m     r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1\u001b[39m, points)  \u001b[38;5;66;03m# radius \u001b[39;00m\n\u001b[1;32m     13\u001b[0m     t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(class_number\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m, (class_number\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m, points) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(points)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     x[ix] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[r\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msin(t\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2.5\u001b[39m), r\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mcos(t\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2.5\u001b[39m)]  \u001b[38;5;66;03m# Dummy features adjusted to 64\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     y[ix] \u001b[38;5;241m=\u001b[39m class_number\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (100,2) could not be broadcast to indexing result of shape (100,64)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Function to create dummy data\n",
    "def create_data(points, classes): \n",
    "    x = np.zeros((points*classes, 64))  # Adjusted to 64 features\n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0, 1, points)  # radius \n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        x[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]  # Dummy features adjusted to 64\n",
    "        y[ix] = class_number\n",
    "    return x, y\n",
    "\n",
    "# Layers and activations\n",
    "class Layer:\n",
    "    def __init__(self, input_size, neuron_size):\n",
    "        self.weights = np.random.randn(input_size, neuron_size) * np.sqrt(2.0 / input_size)\n",
    "        self.biases = np.zeros((1, neuron_size))\n",
    "        self.dw = np.zeros_like(self.weights)\n",
    "        self.db = np.zeros_like(self.biases)\n",
    "        self.v_dw = np.zeros_like(self.weights)\n",
    "        self.v_db = np.zeros_like(self.biases)\n",
    "        self.s_dw = np.zeros_like(self.weights)\n",
    "        self.s_db = np.zeros_like(self.biases)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, inputs, grad_output, learning_rate):\n",
    "        grad_inputs = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(inputs.T, grad_output)\n",
    "        grad_biases = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        \n",
    "        # Adam optimizer\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.999\n",
    "        epsilon = 1e-7\n",
    "\n",
    "        self.v_dw = beta1 * self.v_dw + (1 - beta1) * grad_weights\n",
    "        self.v_db = beta1 * self.v_db + (1 - beta1) * grad_biases\n",
    "        self.s_dw = beta2 * self.s_dw + (1 - beta2) * (grad_weights ** 2)\n",
    "        self.s_db = beta2 * self.s_db + (1 - beta2) * (grad_biases ** 2)\n",
    "        \n",
    "        v_dw_corrected = self.v_dw / (1 - beta1)\n",
    "        v_db_corrected = self.v_db / (1 - beta1)\n",
    "        s_dw_corrected = self.s_dw / (1 - beta2)\n",
    "        s_db_corrected = self.s_db / (1 - beta2)\n",
    "        \n",
    "        self.weights -= learning_rate * v_dw_corrected / (np.sqrt(s_dw_corrected) + epsilon)\n",
    "        self.biases -= learning_rate * v_db_corrected / (np.sqrt(s_db_corrected) + epsilon)\n",
    "\n",
    "class ReluActivation:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class SoftmaxActivation:\n",
    "    def forward(self, inputs):\n",
    "        normalized_inputs = np.exp(inputs - np.amax(inputs, axis=1, keepdims=True))\n",
    "        self.output = normalized_inputs / np.sum(normalized_inputs, axis=1, keepdims=True)\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    @staticmethod\n",
    "    def calculate_loss(y_pred, y_true):\n",
    "        clipped_values = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = clipped_values[range(len(clipped_values)), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(clipped_values * y_true, axis=1)\n",
    "        return np.mean(-np.log(correct_confidences))\n",
    "\n",
    "# Create dummy data with adjusted features\n",
    "X, y = create_data(100, 64)\n",
    "\n",
    "# Initialize layers and activations\n",
    "l1 = Layer(64, 32)  # Adjusted input_size to match features in X\n",
    "ac1 = ReluActivation()\n",
    "l2 = Layer(32, 64)\n",
    "ac2 = SoftmaxActivation()\n",
    "\n",
    "# Forward pass\n",
    "l1.forward(X)\n",
    "ac1.forward(l1.output)\n",
    "l2.forward(ac1.output)\n",
    "ac2.forward(l2.output)\n",
    "\n",
    "# Calculate initial loss\n",
    "initial_loss = CrossEntropyLoss.calculate_loss(ac2.output, y)\n",
    "print(\"Initial Loss:\", initial_loss)\n",
    "\n",
    "# Backward pass (Gradient calculation)\n",
    "grad_ac2 = ac2.output.copy()\n",
    "grad_ac2[range(len(y)), y] -= 1\n",
    "grad_ac2 /= len(y)\n",
    "\n",
    "# Backpropagate gradients\n",
    "ac2_backward = grad_ac2\n",
    "l2.backward(ac1.output, ac2_backward, learning_rate=0.001)\n",
    "\n",
    "ac1_backward = np.dot(ac2_backward, l2.weights.T)\n",
    "l1.backward(X, ac1_backward, learning_rate=0.001)\n",
    "\n",
    "# Re-calculate loss after optimization\n",
    "l1.forward(X)\n",
    "ac1.forward(l1.output)\n",
    "l2.forward(ac1.output)\n",
    "ac2.forward(l2.output)\n",
    "\n",
    "final_loss = CrossEntropyLoss.calculate_loss(ac2.output, y)\n",
    "print(\"Final Loss:\", final_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a4d13-eae9-48a8-b45e-f3772d302225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb665972-1a08-460c-b1c5-320cfb54f349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
