{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d29949-c739-44a2-a2f3-b17961b82108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33332407 0.33178906 0.33488687]\n",
      " [0.33325754 0.32987808 0.33686438]\n",
      " [0.33320352 0.32848265 0.33831383]\n",
      " [0.33323116 0.32659676 0.34017208]]\n",
      "1.1271195200726416\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import abc\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],[4,5,6,7],[8,9,6,5]]\n",
    "\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],[0.5, -0.91, 0.26, -0.5],[-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "def create_data(points, classes): \n",
    "    x = np.zeros((points*classes, 2)) \n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0,1,points) #radius \n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        x[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = class_number\n",
    "    return x, y\n",
    "\n",
    "X, y = create_data(100, 3)\n",
    "# col = np.where(y==0, 'b', y==1, 'k', y==2, 'r')\n",
    "# plt.plot(X[:, 0], X[:, 1], 'o', col=col)\n",
    "        \n",
    "class Layer:\n",
    "    def __init__(self, inputSize, neuronSize):\n",
    "        self.weights = np.random.rand(inputSize, neuronSize)\n",
    "        self.biases = np.zeros((1, neuronSize))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ReluActivation:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class SoftmaxActivation:\n",
    "    def forward(self, inputs):\n",
    "        normalizedInputs = np.exp(inputs - np.amax(inputs, axis=1, keepdims=True))\n",
    "        self.output = normalizedInputs / np.sum(normalizedInputs, axis=1, keepdims=True)\n",
    "\n",
    "class Loss(ABC):\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def loss(self):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        pass\n",
    "\n",
    "class CrossEntropyLoss(Loss):\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.__loss\n",
    "    \n",
    "    def calculate_loss(self, y_pred, y_true):\n",
    "        clippedValues  = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "        if len(y_true.shape) == 1:\n",
    "            correctConfidences = clippedValues[range(len(clippedValues)), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correctConfidences = np.sum(clippedValues*y_true, axis=1)\n",
    "        self.__loss = np.mean(-np.log(correctConfidences))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "X, y = create_data(100, 3)\n",
    "\n",
    "loss = CrossEntropyLoss()\n",
    "\n",
    "l1 = Layer(2, 3)\n",
    "ac1 = ReluActivation()\n",
    "\n",
    "l2 = Layer(3, 3)\n",
    "ac2 = SoftmaxActivation()\n",
    "\n",
    "l1.forward(X)\n",
    "ac1.forward(l1.output)\n",
    "\n",
    "l2.forward(ac1.output)\n",
    "ac2.forward(l2.output)\n",
    "\n",
    "print(ac2.output[:5])\n",
    "\n",
    "loss.calculate_loss(ac2.output, y)\n",
    "print(loss.loss)\n",
    "        \n",
    "# relu = ReluActivation()\n",
    "# l = Layer(4, 5)\n",
    "# l2 = Layer(5, 10)\n",
    "# l.forward(inputs)\n",
    "# l2.forward(l.output)\n",
    "# # print(l2.output)\n",
    "# relu.forward(l2.output)\n",
    "# print(relu.output)\n",
    "\n",
    "#attention score in transformers to see which voice relates the most to the other voice etc\n",
    "#this is also critical in text to speech bcs in words where they are spelt the same like saw and saw need to be able to be \n",
    "#differenciated in text to speech, or like red and read are pronouced the same and thus we\n",
    "#need transformers for predicting which words makes the most sense for what the user inputed \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e8b4f-5d1c-415e-8bb6-d5d4036e1351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
